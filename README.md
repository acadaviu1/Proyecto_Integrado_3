# Proyecto_Integrado_3

Informe de Preparación y Calidad de Datos: Global House PurchaseI. Descripción de Necesidades de LimpiezaAntes de iniciar el procesamiento técnico, se realizó una auditoría detallada del conjunto de datos global_house_purchase.csv para identificar irregularidades que podrían comprometer la validez del análisis. A continuación, se detallan las necesidades detectadas:1. DuplicadosDiagnóstico: Se ha identificado la necesidad de verificar la unicidad de los registros basándose en la columna property_id. Dado que este campo actúa como clave primaria, la existencia de identificadores repetidos indicaría transacciones duplicadas o errores en la extracción de datos.Justificación: Mantener duplicados inflaría artificialmente métricas clave como el conteo de propiedades disponibles o el promedio de precios por región, introduciendo un sesgo positivo en los resultados.2. Valores NulosDiagnóstico: Se observa la presencia de valores faltantes en variables numéricas críticas (como monthly_expenses, loan_amount) y categóricas (como furnishing_status).Justificación:La falta de datos en variables financieras impide el cálculo correcto de ratios como el emi_to_income_ratio.Si la proporción de nulos es baja (<5%), la imputación es viable; si es alta en columnas determinantes para la variable objetivo decision, podría requerir la eliminación de filas para no introducir ruido mediante imputaciones masivas.3. Inconsistencias en ValoresDiagnóstico: Se detectaron inconsistencias en la estandarización de cadenas de texto, específicamente en las columnas country y city. Es probable encontrar variaciones como "USA", "usa" y "United States" refiriéndose a la misma entidad.Justificación: La falta de estandarización fragmenta los grupos durante el análisis. Por ejemplo, al agrupar por país, Python interpretará "USA" y "usa" como dos categorías distintas, distorsionando las estadísticas regionales.4. Tipos de DatosDiagnóstico:La columna constructed_year debe validarse como tipo entero (Integer), ya que un año no debe tener decimales.Las variables categóricas con cardinalidad baja (como property_type o furnishing_status) deben convertirse al tipo category para optimizar memoria.Justificación: El uso de tipos de datos incorrectos no solo consume más recursos computacionales, sino que impide realizar operaciones aritméticas sobre fechas o agrupaciones lógicas sobre categorías.5. Valores Atípicos (Outliers)Diagnóstico: Variables como price (precio de venta) y property_size_sqft (tamaño en pies cuadrados) muestran una alta varianza. Es necesario identificar valores extremos que se alejen significativamente del rango intercuartílico.Justificación: En el sector inmobiliario, una mansión de precio multimillonario o un error de captura (ej. precio $0) pueden desviar drásticamente la media, haciendo que el promedio no sea representativo del mercado general.Shutterstock6. Nivel de GranularidadDiagnóstico: El dataset actual presenta una granularidad a nivel de transacción individual (una fila por propiedad).Evaluación: Este nivel es el adecuado para el objetivo de modelado predictivo (clasificar si se compra o no). Sin embargo, para la generación de reportes ejecutivos sobre tendencias de mercado, el nivel de detalle es excesivo y se requiere una agregación posterior por país o tipo de propiedad.II. Limpieza y Transformación de DatosCon base en el diagnóstico anterior, se establece la siguiente ruta metodológica para la depuración del dataset:1. Eliminación de DuplicadosAcción: Se procederá a eliminar las filas duplicadas tomando como referencia la columna property_id, conservando únicamente la primera aparición (keep='first').Resultado esperado: Un dataset con integridad referencial única, donde cada fila representa una propiedad distinta, eliminando el riesgo de conteo doble.2. Tratamiento de Valores NulosSe aplicará una estrategia híbrida dependiendo de la naturaleza de la variable:Variables Numéricas (Imputación): Para columnas como monthly_expenses o customer_salary, se rellenarán los valores faltantes utilizando la Mediana. Se selecciona la mediana en lugar de la media debido a su robustez frente a los valores atípicos detectados en los salarios y precios.Variables Categóricas (Imputación): Para furnishing_status y property_type, se imputarán los nulos utilizando la Moda (el valor más frecuente), asumiendo que la propiedad faltante sigue la tendencia mayoritaria del mercado.Eliminación: Si persisten filas con nulos en la variable objetivo decision, estas serán eliminadas, ya que no se puede entrenar un modelo supervisado sin la etiqueta de clase real.3. Ajuste de Tipos de DatosConversión: Se forzará la conversión de constructed_year a número entero.Optimización: Se convertirán las columnas de texto con valores repetitivos (country, property_type) al tipo de dato category de pandas. Esto asegura que el análisis posterior trate estas variables como factores cualitativos y no como texto libre.4. Detección y Tratamiento de Valores AtípicosTécnica: Se utilizará el método del Rango Intercuartílico (IQR). Se calcularán el primer (Q1) y tercer cuartil (Q3) para la variable price.Acción: Se filtrarán y excluirán del dataset aquellos registros que se encuentren fuera del rango $[Q1 - 1.5*IQR, Q3 + 1.5*IQR]$.Justificación: Esto eliminará errores de captura y propiedades de ultra-lujo que no corresponden al segmento de mercado objetivo del análisis general, normalizando la distribución de precios.5. Correcciones de Valores (Estandarización)Normalización de Texto: Se aplicarán funciones de mapeo (map o replace) para unificar los nombres de los países (ej. transformar todas las variaciones a "USA", "UK", etc.).Decodificación (Opcional): Si es necesario para la legibilidad humana en los gráficos, se mapeará la variable decision (0 y 1) a etiquetas descriptivas como "No Compra" y "Compra".6. Agregación de DatosObjetivo: Generar una vista resumida para el análisis de tendencias regionales.Método: Se creará un sub-conjunto de datos agrupado mediante groupby por las columnas country y property_type.Funciones de Agregación: Se calculará el promedio (mean) del price y el satisfaction_score, y el conteo (count) de property_id para entender el volumen de oferta por región.
